// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple riscv64 -target-feature +experimental-matrix \
// RUN: -target-feature +experimental-v -target-feature +f -target-feature +d \
// RUN: -target-feature +experimental-zfh -disable-O0-optnone -emit-llvm %s -o - \
// RUN: | opt -S -mem2reg | FileCheck --check-prefix=CHECK-IR-RV64 %s


#include <riscv_matrix.h>

// CHECK-IR-RV64-LABEL: @test_mfcvt_x_f_m_i16m1(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast half* [[IN1:%.*]] to <vscale x 64 x half>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 64 x half> @llvm.riscv.mlae.m.nxv64f16.i64(<vscale x 64 x half>* [[TMP0]], i64 [[A:%.*]], i64 0) #[[ATTR6:[0-9]+]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 64 x i16> @llvm.riscv.mfcvt.x.f.m.nxv64i16.nxv64f16.i64(<vscale x 64 x half> [[TMP1]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i16* [[OUT:%.*]] to <vscale x 64 x i16>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv64i16.i64(<vscale x 64 x i16> [[TMP2]], <vscale x 64 x i16>* [[TMP3]], i64 [[A]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfcvt_x_f_m_i16m1(const _Float16 *in1, int16_t *out, size_t a) {
    mfloat16m1_t m1 = mlae16_m1(in1, a);
    mint16m1_t mo = mfcvt_x_f_m(m1);
    msae16_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfcvt_x_f_m_i32m1(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast float* [[IN1:%.*]] to <vscale x 32 x float>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 32 x float> @llvm.riscv.mlae.m.nxv32f32.i64(<vscale x 32 x float>* [[TMP0]], i64 [[A:%.*]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 32 x i32> @llvm.riscv.mfcvt.x.f.m.nxv32i32.nxv32f32.i64(<vscale x 32 x float> [[TMP1]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i32* [[OUT:%.*]] to <vscale x 32 x i32>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv32i32.i64(<vscale x 32 x i32> [[TMP2]], <vscale x 32 x i32>* [[TMP3]], i64 [[A]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfcvt_x_f_m_i32m1(const float *in1, int32_t *out, size_t a) {
    mfloat32m1_t m1 = mlae32_m1(in1, a);
    mint32m1_t mo = mfcvt_x_f_m(m1);
    msae32_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfcvt_x_f_m_i64m1(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast double* [[IN1:%.*]] to <vscale x 16 x double>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 16 x double> @llvm.riscv.mlae.m.nxv16f64.i64(<vscale x 16 x double>* [[TMP0]], i64 [[A:%.*]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 16 x i64> @llvm.riscv.mfcvt.x.f.m.nxv16i64.nxv16f64.i64(<vscale x 16 x double> [[TMP1]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i64* [[OUT:%.*]] to <vscale x 16 x i64>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv16i64.i64(<vscale x 16 x i64> [[TMP2]], <vscale x 16 x i64>* [[TMP3]], i64 [[A]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfcvt_x_f_m_i64m1(const double *in1, int64_t *out, size_t a) {
    mfloat64m1_t m1 = mlae64_m1(in1, a);
    mint64m1_t mo = mfcvt_x_f_m(m1);
    msae64_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfwcvt_xw_f_m_i32m2(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast half* [[IN1:%.*]] to <vscale x 64 x half>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 64 x half> @llvm.riscv.mlae.m.nxv64f16.i64(<vscale x 64 x half>* [[TMP0]], i64 [[A:%.*]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 64 x i32> @llvm.riscv.mfwcvt.xw.f.m.nxv64i32.nxv64f16.i64(<vscale x 64 x half> [[TMP1]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i32* [[OUT:%.*]] to <vscale x 64 x i32>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv64i32.i64(<vscale x 64 x i32> [[TMP2]], <vscale x 64 x i32>* [[TMP3]], i64 [[A]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfwcvt_xw_f_m_i32m2(const _Float16 *in1, int32_t *out, size_t a) {
    mfloat16m1_t m1 = mlae16_m1(in1, a);
    mint32m2_t mo = mfwcvt_xw_f_m(m1);
    msae32_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfwcvt_xw_f_m_i64m2(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast float* [[IN1:%.*]] to <vscale x 32 x float>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 32 x float> @llvm.riscv.mlae.m.nxv32f32.i64(<vscale x 32 x float>* [[TMP0]], i64 [[A:%.*]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 32 x i64> @llvm.riscv.mfwcvt.xw.f.m.nxv32i64.nxv32f32.i64(<vscale x 32 x float> [[TMP1]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i64* [[OUT:%.*]] to <vscale x 32 x i64>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv32i64.i64(<vscale x 32 x i64> [[TMP2]], <vscale x 32 x i64>* [[TMP3]], i64 [[A]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfwcvt_xw_f_m_i64m2(const float *in1, int64_t *out, size_t a) {
    mfloat32m1_t m1 = mlae32_m1(in1, a);
    mint64m2_t mo = mfwcvt_xw_f_m(m1);
    msae64_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfwcvt_xq_f_m_i64m4(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast half* [[IN1:%.*]] to <vscale x 64 x half>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 64 x half> @llvm.riscv.mlae.m.nxv64f16.i64(<vscale x 64 x half>* [[TMP0]], i64 [[A:%.*]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 64 x i64> @llvm.riscv.mfwcvt.xq.f.m.nxv64i64.nxv64f16.i64(<vscale x 64 x half> [[TMP1]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i64* [[OUT:%.*]] to <vscale x 64 x i64>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv64i64.i64(<vscale x 64 x i64> [[TMP2]], <vscale x 64 x i64>* [[TMP3]], i64 [[A]], i64 2) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfwcvt_xq_f_m_i64m4(const _Float16 *in1, int64_t *out, size_t a) {
    mfloat16m1_t m1 = mlae16_m1(in1, a);
    mint64m4_t mo = mfwcvt_xq_f_m(m1);
    msae64_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfncvt_x_fw_m_i8m1(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast half* [[IN1:%.*]] to <vscale x 128 x half>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 128 x half> @llvm.riscv.mlae.m.nxv128f16.i64(<vscale x 128 x half>* [[TMP0]], i64 [[A:%.*]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 128 x i8> @llvm.riscv.mfncvt.x.fw.m.nxv128i8.nxv128f16.i64(<vscale x 128 x half> [[TMP1]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i8* [[OUT:%.*]] to <vscale x 128 x i8>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv128i8.i64(<vscale x 128 x i8> [[TMP2]], <vscale x 128 x i8>* [[TMP3]], i64 [[A]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfncvt_x_fw_m_i8m1(const _Float16 *in1, int8_t *out, size_t a) {
    mfloat16m2_t m1 = mlae16_m2(in1, a);
    mint8m1_t mo = mfncvt_x_fw_m(m1);
    msae8_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfncvt_x_fw_m_i16m1(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast float* [[IN1:%.*]] to <vscale x 64 x float>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 64 x float> @llvm.riscv.mlae.m.nxv64f32.i64(<vscale x 64 x float>* [[TMP0]], i64 [[A:%.*]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 64 x i16> @llvm.riscv.mfncvt.x.fw.m.nxv64i16.nxv64f32.i64(<vscale x 64 x float> [[TMP1]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i16* [[OUT:%.*]] to <vscale x 64 x i16>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv64i16.i64(<vscale x 64 x i16> [[TMP2]], <vscale x 64 x i16>* [[TMP3]], i64 [[A]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfncvt_x_fw_m_i16m1(const float *in1, int16_t *out, size_t a) {
    mfloat32m2_t m1 = mlae32_m2(in1, a);
    mint16m1_t mo = mfncvt_x_fw_m(m1);
    msae16_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfncvt_x_fw_m_i32m1(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast double* [[IN1:%.*]] to <vscale x 32 x double>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 32 x double> @llvm.riscv.mlae.m.nxv32f64.i64(<vscale x 32 x double>* [[TMP0]], i64 [[A:%.*]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 32 x i32> @llvm.riscv.mfncvt.x.fw.m.nxv32i32.nxv32f64.i64(<vscale x 32 x double> [[TMP1]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i32* [[OUT:%.*]] to <vscale x 32 x i32>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv32i32.i64(<vscale x 32 x i32> [[TMP2]], <vscale x 32 x i32>* [[TMP3]], i64 [[A]], i64 0) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfncvt_x_fw_m_i32m1(const double *in1, int32_t *out, size_t a) {
    mfloat64m2_t m1 = mlae64_m2(in1, a);
    mint32m1_t mo = mfncvt_x_fw_m(m1);
    msae32_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfcvt_xw_fw_m_i32m2(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast float* [[IN1:%.*]] to <vscale x 64 x float>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 64 x float> @llvm.riscv.mlae.m.nxv64f32.i64(<vscale x 64 x float>* [[TMP0]], i64 [[A:%.*]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 64 x i32> @llvm.riscv.mfcvt.xw.fw.m.nxv64i32.nxv64f32.i64(<vscale x 64 x float> [[TMP1]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i32* [[OUT:%.*]] to <vscale x 64 x i32>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv64i32.i64(<vscale x 64 x i32> [[TMP2]], <vscale x 64 x i32>* [[TMP3]], i64 [[A]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfcvt_xw_fw_m_i32m2(const float *in1, int32_t *out, size_t a) {
    mfloat32m2_t m1 = mlae32_m2(in1, a);
    mint32m2_t mo = mfcvt_xw_fw_m(m1);
    msae32_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfcvt_xw_fw_m_i64m2(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast double* [[IN1:%.*]] to <vscale x 32 x double>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 32 x double> @llvm.riscv.mlae.m.nxv32f64.i64(<vscale x 32 x double>* [[TMP0]], i64 [[A:%.*]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 32 x i64> @llvm.riscv.mfcvt.xw.fw.m.nxv32i64.nxv32f64.i64(<vscale x 32 x double> [[TMP1]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i64* [[OUT:%.*]] to <vscale x 32 x i64>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv32i64.i64(<vscale x 32 x i64> [[TMP2]], <vscale x 32 x i64>* [[TMP3]], i64 [[A]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfcvt_xw_fw_m_i64m2(const double *in1, int64_t *out, size_t a) {
    mfloat64m2_t m1 = mlae64_m2(in1, a);
    mint64m2_t mo = mfcvt_xw_fw_m(m1);
    msae64_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfwcvt_xq_fw_m_i64m4(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast float* [[IN1:%.*]] to <vscale x 64 x float>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 64 x float> @llvm.riscv.mlae.m.nxv64f32.i64(<vscale x 64 x float>* [[TMP0]], i64 [[A:%.*]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 64 x i64> @llvm.riscv.mfwcvt.xq.fw.m.nxv64i64.nxv64f32.i64(<vscale x 64 x float> [[TMP1]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i64* [[OUT:%.*]] to <vscale x 64 x i64>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv64i64.i64(<vscale x 64 x i64> [[TMP2]], <vscale x 64 x i64>* [[TMP3]], i64 [[A]], i64 2) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfwcvt_xq_fw_m_i64m4(const float *in1, int64_t *out, size_t a) {
    mfloat32m2_t m1 = mlae32_m2(in1, a);
    mint64m4_t mo = mfwcvt_xq_fw_m(m1);
    msae64_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfcvt_x_f_m_i16m2(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast half* [[IN1:%.*]] to <vscale x 128 x half>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 128 x half> @llvm.riscv.mlae.m.nxv128f16.i64(<vscale x 128 x half>* [[TMP0]], i64 [[A:%.*]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 128 x i16> @llvm.riscv.mfcvt.x.f.m.nxv128i16.nxv128f16.i64(<vscale x 128 x half> [[TMP1]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i16* [[OUT:%.*]] to <vscale x 128 x i16>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv128i16.i64(<vscale x 128 x i16> [[TMP2]], <vscale x 128 x i16>* [[TMP3]], i64 [[A]], i64 1) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfcvt_x_f_m_i16m2(const _Float16 *in1, int16_t *out, size_t a) {
    mfloat16m2_t m1 = mlae16_m2(in1, a);
    mint16m2_t mo = mfcvt_x_f_m(m1);
    msae16_m(mo, out, a);
    return;
}

// CHECK-IR-RV64-LABEL: @test_mfcvt_x_f_m_i16m4(
// CHECK-IR-RV64-NEXT:  entry:
// CHECK-IR-RV64-NEXT:    [[TMP0:%.*]] = bitcast half* [[IN1:%.*]] to <vscale x 256 x half>*
// CHECK-IR-RV64-NEXT:    [[TMP1:%.*]] = call <vscale x 256 x half> @llvm.riscv.mlae.m.nxv256f16.i64(<vscale x 256 x half>* [[TMP0]], i64 [[A:%.*]], i64 2) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP2:%.*]] = call <vscale x 256 x i16> @llvm.riscv.mfcvt.x.f.m.nxv256i16.nxv256f16.i64(<vscale x 256 x half> [[TMP1]], i64 2) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    [[TMP3:%.*]] = bitcast i16* [[OUT:%.*]] to <vscale x 256 x i16>*
// CHECK-IR-RV64-NEXT:    call void @llvm.riscv.msae.m.nxv256i16.i64(<vscale x 256 x i16> [[TMP2]], <vscale x 256 x i16>* [[TMP3]], i64 [[A]], i64 2) #[[ATTR6]]
// CHECK-IR-RV64-NEXT:    ret void
//
void test_mfcvt_x_f_m_i16m4(const _Float16 *in1, int16_t *out, size_t a) {
    mfloat16m4_t m1 = mlae16_m4(in1, a);
    mint16m4_t mo = mfcvt_x_f_m(m1);
    msae16_m(mo, out, a);
    return;
}

